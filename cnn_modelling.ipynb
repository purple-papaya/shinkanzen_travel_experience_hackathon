{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder, KBinsDiscretizer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout, Dense,  ReLU\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomOrdinalEncoder:\n",
    "    def __init__(self, categories):\n",
    "        self.categories = categories\n",
    "        self.cat_to_int = {}\n",
    "        self.int_to_cat = {}\n",
    "        for i, cat in enumerate(self.categories):\n",
    "            self.cat_to_int[cat] = i\n",
    "            self.int_to_cat[i] = cat\n",
    "\n",
    "    def transform(self, data):\n",
    "        return np.array([self.cat_to_int[cat] if cat in self.cat_to_int else np.nan for cat in data])\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        return np.array([self.int_to_cat[int(cat)] for cat in data])\n",
    "\n",
    "def encode_ordinal_columns(df, ordinal_columns, n_classes):\n",
    "    encoders = {}\n",
    "    encoded_df = df.copy()\n",
    "    for col in ordinal_columns:\n",
    "        unique_values = sorted(df[col].dropna().unique())\n",
    "        categories = unique_values + [f\"extra_class_{i}\" for i in range(n_classes - len(unique_values))]\n",
    "        encoder = CustomOrdinalEncoder(categories)\n",
    "        encoded_df[col] = encoder.transform(df[col])\n",
    "        encoders[col] = encoder\n",
    "    return encoded_df, encoders\n",
    "\n",
    "def impute_missing_ordinal_records(df, ordinal_columns, n_classes=5, max_iter=10, random_state=42):\n",
    "    encoded_df, encoders = encode_ordinal_columns(df, ordinal_columns, n_classes)\n",
    "    \n",
    "    imputer = IterativeImputer(max_iter=max_iter, estimator=RandomForestRegressor(random_state=random_state), random_state=random_state)\n",
    "    imputed_array = imputer.fit_transform(encoded_df)\n",
    "\n",
    "    imputed_df = pd.DataFrame(imputed_array, columns=df.columns)\n",
    "    imputed_df[ordinal_columns] = np.round(imputed_df[ordinal_columns])\n",
    "\n",
    "    for col in ordinal_columns:\n",
    "        imputed_df[col] = encoders[col].inverse_transform(imputed_df[col])\n",
    "\n",
    "    return imputed_df\n",
    "\n",
    "def encode_non_ordinal_columns(df, non_ordinal_columns):\n",
    "    encoded_df = pd.get_dummies(df, columns=non_ordinal_columns, drop_first=True)\n",
    "    return encoded_df\n",
    "\n",
    "def impute_missing_non_ordinal_records(df, max_iter=10, random_state=42):\n",
    "    imputer = IterativeImputer(max_iter=max_iter, estimator=RandomForestRegressor(random_state=random_state), random_state=random_state)\n",
    "    imputed_array = imputer.fit_transform(df)\n",
    "\n",
    "    imputed_df = pd.DataFrame(imputed_array, columns=df.columns)\n",
    "    return imputed_df\n",
    "\n",
    "def impute_most_common(df):\n",
    "    for column in df.columns:\n",
    "        most_common_value = df[column].mode()[0]\n",
    "        df[column].fillna(most_common_value, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df = pd.read_csv('Surveydata_train.csv', )\n",
    "survey_df_test = pd.read_csv('Surveydata_test.csv')\n",
    "\n",
    "travel_df = pd.read_csv('Traveldata_train.csv')\n",
    "travel_df_test = pd.read_csv('Traveldata_test.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(survey_df, travel_df, on= 'ID')\n",
    "merged_df_test = pd.merge(survey_df_test, travel_df_test, on= 'ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Business Travel    58617\n",
       "Personal Travel    26536\n",
       "Name: Type_Travel, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['Type_Travel'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df = (\n",
    "    merged_df\n",
    "    # 'Seat_comfort', 'Arrival_time_convenient', 'Catering', 'Onboardwifi_service', 'Onboard_entertainment', 'Online_support',\n",
    "    # 'Onlinebooking_Ease', 'Onboard_service', 'Leg_room', 'Checkin_service', 'Cleanliness', 'Online_boarding'\n",
    "    .replace(['Excellent', 'Good', 'Acceptable', 'Needs Improvement', 'Poor', 'Extremely Poor'], [5, 4, 3, 2, 1, 0])\n",
    "    # Platform_location\n",
    "    .replace(['Very Convenient', 'Convenient', 'Manageable', 'Needs Improvement', 'Inconvenient', 'Very Inconvenient'], [5, 4, 3, 2, 1, 0])\n",
    "    # Seat_Class\n",
    "    .replace(['Ordinary', 'Green Car'], [0, 1])\n",
    "    # Gender\n",
    "    .replace(['Male', 'Female'], [0, 1])\n",
    "    # CustomerType\n",
    "    .replace(['Disloyal Customer', 'Loyal Customer'], [0, 1])\n",
    "    # TypeTravel\n",
    "    .replace(['Personal Travel', 'Business Travel'], [0, 1])\n",
    "    # Travel_Class\n",
    "    .replace(['Eco', 'Business'], [0, 1])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_test_df = (\n",
    "    merged_df_test\n",
    "    .replace(['Excellent', 'Good', 'Acceptable', 'Needs Improvement', 'Poor', 'Extremely Poor'], [5, 4, 3, 2, 1, 0])\n",
    "    .replace(['Very Convenient', 'Convenient', 'Manageable', 'Needs Improvement', 'Inconvenient', 'Very Inconvenient'], [5, 4, 3, 2, 1, 0])\n",
    "    .replace(['Ordinary', 'Green Car'], [0, 1])\n",
    "    .replace(['Male', 'Female'], [0, 1])\n",
    "    .replace(['Disloyal Customer', 'Loyal Customer'], [0, 1])\n",
    "    .replace(['Personal Travel', 'Business Travel'], [0, 1])\n",
    "    .replace(['Eco', 'Business'], [0, 1])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df['Age'] = pd.cut(transformed_df['Age'], 5, labels = ['25', '35', '45', '60', '80'])\n",
    "transformed_test_df['Age'] = pd.cut(transformed_test_df['Age'], 5, labels = ['25', '35', '45', '60', '80'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_columns = [\n",
    "    'Seat_Comfort', 'Arrival_Time_Convenient', 'Catering', 'Platform_Location', 'Onboard_Wifi_Service', \n",
    "    'Onboard_Entertainment', 'Online_Support', 'Ease_of_Online_Booking', 'Onboard_Service', \n",
    "    'Legroom', 'Baggage_Handling', 'CheckIn_Service', 'Cleanliness', 'Online_Boarding'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [\n",
    "    'Seat_Class', 'Gender', 'Customer_Type', 'Type_Travel', 'Travel_Class', 'Age'\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train data imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pavlina_novakova/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_iterative.py:699: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ordinal_imputed = impute_missing_ordinal_records(transformed_df[ordinal_columns], ordinal_columns, n_classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_non_ordinal_df = encode_non_ordinal_columns(transformed_df[categorical_columns], categorical_columns)\n",
    "ordinal_imputed['ID'] = transformed_df['ID']\n",
    "encoded_non_ordinal_df['ID'] = transformed_df['ID']\n",
    "\n",
    "encoded_df = pd.merge(encoded_non_ordinal_df, ordinal_imputed, on= 'ID')\n",
    "\n",
    "categorical_imputed = impute_missing_non_ordinal_records(encoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = encode_non_ordinal_columns(categorical_imputed.copy().drop(['ID'], axis=1), ordinal_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 94379 entries, 0 to 94378\n",
      "Data columns (total 78 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   Seat_Class_1                 94379 non-null  float64\n",
      " 1   Gender_1.0                   94379 non-null  float64\n",
      " 2   Customer_Type_1.0            94379 non-null  float64\n",
      " 3   Type_Travel_1.0              94379 non-null  float64\n",
      " 4   Travel_Class_1               94379 non-null  float64\n",
      " 5   Age_35                       94379 non-null  float64\n",
      " 6   Age_45                       94379 non-null  float64\n",
      " 7   Age_60                       94379 non-null  float64\n",
      " 8   Age_80                       94379 non-null  float64\n",
      " 9   Seat_Comfort_1.0             94379 non-null  uint8  \n",
      " 10  Seat_Comfort_2.0             94379 non-null  uint8  \n",
      " 11  Seat_Comfort_3.0             94379 non-null  uint8  \n",
      " 12  Seat_Comfort_4.0             94379 non-null  uint8  \n",
      " 13  Seat_Comfort_5.0             94379 non-null  uint8  \n",
      " 14  Arrival_Time_Convenient_1.0  94379 non-null  uint8  \n",
      " 15  Arrival_Time_Convenient_2.0  94379 non-null  uint8  \n",
      " 16  Arrival_Time_Convenient_3.0  94379 non-null  uint8  \n",
      " 17  Arrival_Time_Convenient_4.0  94379 non-null  uint8  \n",
      " 18  Arrival_Time_Convenient_5.0  94379 non-null  uint8  \n",
      " 19  Catering_1.0                 94379 non-null  uint8  \n",
      " 20  Catering_2.0                 94379 non-null  uint8  \n",
      " 21  Catering_3.0                 94379 non-null  uint8  \n",
      " 22  Catering_4.0                 94379 non-null  uint8  \n",
      " 23  Catering_5.0                 94379 non-null  uint8  \n",
      " 24  Platform_Location_1.0        94379 non-null  uint8  \n",
      " 25  Platform_Location_2.0        94379 non-null  uint8  \n",
      " 26  Platform_Location_3.0        94379 non-null  uint8  \n",
      " 27  Platform_Location_4.0        94379 non-null  uint8  \n",
      " 28  Platform_Location_5.0        94379 non-null  uint8  \n",
      " 29  Onboard_Wifi_Service_1.0     94379 non-null  uint8  \n",
      " 30  Onboard_Wifi_Service_2.0     94379 non-null  uint8  \n",
      " 31  Onboard_Wifi_Service_3.0     94379 non-null  uint8  \n",
      " 32  Onboard_Wifi_Service_4.0     94379 non-null  uint8  \n",
      " 33  Onboard_Wifi_Service_5.0     94379 non-null  uint8  \n",
      " 34  Onboard_Entertainment_1.0    94379 non-null  uint8  \n",
      " 35  Onboard_Entertainment_2.0    94379 non-null  uint8  \n",
      " 36  Onboard_Entertainment_3.0    94379 non-null  uint8  \n",
      " 37  Onboard_Entertainment_4.0    94379 non-null  uint8  \n",
      " 38  Onboard_Entertainment_5.0    94379 non-null  uint8  \n",
      " 39  Online_Support_1.0           94379 non-null  uint8  \n",
      " 40  Online_Support_2.0           94379 non-null  uint8  \n",
      " 41  Online_Support_3.0           94379 non-null  uint8  \n",
      " 42  Online_Support_4.0           94379 non-null  uint8  \n",
      " 43  Online_Support_5.0           94379 non-null  uint8  \n",
      " 44  Ease_of_Online_Booking_1.0   94379 non-null  uint8  \n",
      " 45  Ease_of_Online_Booking_2.0   94379 non-null  uint8  \n",
      " 46  Ease_of_Online_Booking_3.0   94379 non-null  uint8  \n",
      " 47  Ease_of_Online_Booking_4.0   94379 non-null  uint8  \n",
      " 48  Ease_of_Online_Booking_5.0   94379 non-null  uint8  \n",
      " 49  Onboard_Service_1.0          94379 non-null  uint8  \n",
      " 50  Onboard_Service_2.0          94379 non-null  uint8  \n",
      " 51  Onboard_Service_3.0          94379 non-null  uint8  \n",
      " 52  Onboard_Service_4.0          94379 non-null  uint8  \n",
      " 53  Onboard_Service_5.0          94379 non-null  uint8  \n",
      " 54  Legroom_1.0                  94379 non-null  uint8  \n",
      " 55  Legroom_2.0                  94379 non-null  uint8  \n",
      " 56  Legroom_3.0                  94379 non-null  uint8  \n",
      " 57  Legroom_4.0                  94379 non-null  uint8  \n",
      " 58  Legroom_5.0                  94379 non-null  uint8  \n",
      " 59  Baggage_Handling_2.0         94379 non-null  uint8  \n",
      " 60  Baggage_Handling_3.0         94379 non-null  uint8  \n",
      " 61  Baggage_Handling_4.0         94379 non-null  uint8  \n",
      " 62  Baggage_Handling_5.0         94379 non-null  uint8  \n",
      " 63  CheckIn_Service_1.0          94379 non-null  uint8  \n",
      " 64  CheckIn_Service_2.0          94379 non-null  uint8  \n",
      " 65  CheckIn_Service_3.0          94379 non-null  uint8  \n",
      " 66  CheckIn_Service_4.0          94379 non-null  uint8  \n",
      " 67  CheckIn_Service_5.0          94379 non-null  uint8  \n",
      " 68  Cleanliness_1.0              94379 non-null  uint8  \n",
      " 69  Cleanliness_2.0              94379 non-null  uint8  \n",
      " 70  Cleanliness_3.0              94379 non-null  uint8  \n",
      " 71  Cleanliness_4.0              94379 non-null  uint8  \n",
      " 72  Cleanliness_5.0              94379 non-null  uint8  \n",
      " 73  Online_Boarding_1.0          94379 non-null  uint8  \n",
      " 74  Online_Boarding_2.0          94379 non-null  uint8  \n",
      " 75  Online_Boarding_3.0          94379 non-null  uint8  \n",
      " 76  Online_Boarding_4.0          94379 non-null  uint8  \n",
      " 77  Online_Boarding_5.0          94379 non-null  uint8  \n",
      "dtypes: float64(9), uint8(69)\n",
      "memory usage: 12.7 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(final_df.info())\n",
    "display(len(final_df.columns))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test data imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pavlina_novakova/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_iterative.py:699: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ordinal_test_imputed = impute_missing_ordinal_records(transformed_test_df[ordinal_columns], ordinal_columns, n_classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_test_non_ordinal_df = encode_non_ordinal_columns(transformed_test_df[categorical_columns], categorical_columns)\n",
    "ordinal_test_imputed['ID'] = transformed_test_df['ID']\n",
    "encoded_test_non_ordinal_df['ID'] = transformed_test_df['ID']\n",
    "\n",
    "encoded_test_df = pd.merge(encoded_test_non_ordinal_df, ordinal_test_imputed, on= 'ID')\n",
    "\n",
    "categorical_test_imputed = impute_missing_non_ordinal_records(encoded_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_df = (\n",
    "    encode_non_ordinal_columns(categorical_test_imputed.copy().drop(['ID'], axis=1), ordinal_columns)\n",
    ")\n",
    "\n",
    "final_test_df['CheckIn_Service_1.0'] = 0\n",
    "final_test_df['Cleanliness_1.0'] = 0\n",
    "final_test_df['Onboard_Service_1.0'] = 0\n",
    "final_test_df['Online_Support_1.0'] = 0\n",
    "final_test_df['Platform_Location_1.0'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35602 entries, 0 to 35601\n",
      "Data columns (total 78 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   Seat_Class_1                 35602 non-null  float64\n",
      " 1   Gender_1.0                   35602 non-null  float64\n",
      " 2   Customer_Type_1.0            35602 non-null  float64\n",
      " 3   Type_Travel_1.0              35602 non-null  float64\n",
      " 4   Travel_Class_1               35602 non-null  float64\n",
      " 5   Age_35                       35602 non-null  float64\n",
      " 6   Age_45                       35602 non-null  float64\n",
      " 7   Age_60                       35602 non-null  float64\n",
      " 8   Age_80                       35602 non-null  float64\n",
      " 9   Seat_Comfort_1.0             35602 non-null  uint8  \n",
      " 10  Seat_Comfort_2.0             35602 non-null  uint8  \n",
      " 11  Seat_Comfort_3.0             35602 non-null  uint8  \n",
      " 12  Seat_Comfort_4.0             35602 non-null  uint8  \n",
      " 13  Seat_Comfort_5.0             35602 non-null  uint8  \n",
      " 14  Arrival_Time_Convenient_1.0  35602 non-null  uint8  \n",
      " 15  Arrival_Time_Convenient_2.0  35602 non-null  uint8  \n",
      " 16  Arrival_Time_Convenient_3.0  35602 non-null  uint8  \n",
      " 17  Arrival_Time_Convenient_4.0  35602 non-null  uint8  \n",
      " 18  Arrival_Time_Convenient_5.0  35602 non-null  uint8  \n",
      " 19  Catering_1.0                 35602 non-null  uint8  \n",
      " 20  Catering_2.0                 35602 non-null  uint8  \n",
      " 21  Catering_3.0                 35602 non-null  uint8  \n",
      " 22  Catering_4.0                 35602 non-null  uint8  \n",
      " 23  Catering_5.0                 35602 non-null  uint8  \n",
      " 24  Platform_Location_2.0        35602 non-null  uint8  \n",
      " 25  Platform_Location_3.0        35602 non-null  uint8  \n",
      " 26  Platform_Location_4.0        35602 non-null  uint8  \n",
      " 27  Platform_Location_5.0        35602 non-null  uint8  \n",
      " 28  Onboard_Wifi_Service_1.0     35602 non-null  uint8  \n",
      " 29  Onboard_Wifi_Service_2.0     35602 non-null  uint8  \n",
      " 30  Onboard_Wifi_Service_3.0     35602 non-null  uint8  \n",
      " 31  Onboard_Wifi_Service_4.0     35602 non-null  uint8  \n",
      " 32  Onboard_Wifi_Service_5.0     35602 non-null  uint8  \n",
      " 33  Onboard_Entertainment_1.0    35602 non-null  uint8  \n",
      " 34  Onboard_Entertainment_2.0    35602 non-null  uint8  \n",
      " 35  Onboard_Entertainment_3.0    35602 non-null  uint8  \n",
      " 36  Onboard_Entertainment_4.0    35602 non-null  uint8  \n",
      " 37  Onboard_Entertainment_5.0    35602 non-null  uint8  \n",
      " 38  Online_Support_2.0           35602 non-null  uint8  \n",
      " 39  Online_Support_3.0           35602 non-null  uint8  \n",
      " 40  Online_Support_4.0           35602 non-null  uint8  \n",
      " 41  Online_Support_5.0           35602 non-null  uint8  \n",
      " 42  Ease_of_Online_Booking_1.0   35602 non-null  uint8  \n",
      " 43  Ease_of_Online_Booking_2.0   35602 non-null  uint8  \n",
      " 44  Ease_of_Online_Booking_3.0   35602 non-null  uint8  \n",
      " 45  Ease_of_Online_Booking_4.0   35602 non-null  uint8  \n",
      " 46  Ease_of_Online_Booking_5.0   35602 non-null  uint8  \n",
      " 47  Onboard_Service_2.0          35602 non-null  uint8  \n",
      " 48  Onboard_Service_3.0          35602 non-null  uint8  \n",
      " 49  Onboard_Service_4.0          35602 non-null  uint8  \n",
      " 50  Onboard_Service_5.0          35602 non-null  uint8  \n",
      " 51  Legroom_1.0                  35602 non-null  uint8  \n",
      " 52  Legroom_2.0                  35602 non-null  uint8  \n",
      " 53  Legroom_3.0                  35602 non-null  uint8  \n",
      " 54  Legroom_4.0                  35602 non-null  uint8  \n",
      " 55  Legroom_5.0                  35602 non-null  uint8  \n",
      " 56  Baggage_Handling_2.0         35602 non-null  uint8  \n",
      " 57  Baggage_Handling_3.0         35602 non-null  uint8  \n",
      " 58  Baggage_Handling_4.0         35602 non-null  uint8  \n",
      " 59  Baggage_Handling_5.0         35602 non-null  uint8  \n",
      " 60  CheckIn_Service_2.0          35602 non-null  uint8  \n",
      " 61  CheckIn_Service_3.0          35602 non-null  uint8  \n",
      " 62  CheckIn_Service_4.0          35602 non-null  uint8  \n",
      " 63  CheckIn_Service_5.0          35602 non-null  uint8  \n",
      " 64  Cleanliness_2.0              35602 non-null  uint8  \n",
      " 65  Cleanliness_3.0              35602 non-null  uint8  \n",
      " 66  Cleanliness_4.0              35602 non-null  uint8  \n",
      " 67  Cleanliness_5.0              35602 non-null  uint8  \n",
      " 68  Online_Boarding_1.0          35602 non-null  uint8  \n",
      " 69  Online_Boarding_2.0          35602 non-null  uint8  \n",
      " 70  Online_Boarding_3.0          35602 non-null  uint8  \n",
      " 71  Online_Boarding_4.0          35602 non-null  uint8  \n",
      " 72  Online_Boarding_5.0          35602 non-null  uint8  \n",
      " 73  CheckIn_Service_1.0          35602 non-null  int64  \n",
      " 74  Cleanliness_1.0              35602 non-null  int64  \n",
      " 75  Onboard_Service_1.0          35602 non-null  int64  \n",
      " 76  Online_Support_1.0           35602 non-null  int64  \n",
      " 77  Platform_Location_1.0        35602 non-null  int64  \n",
      "dtypes: float64(9), int64(5), uint8(64)\n",
      "memory usage: 6.0 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(final_test_df.info())\n",
    "display(len(final_test_df.columns))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = StandardScaler()\n",
    "standard_scaled_data = standard_scaler.fit_transform(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pavlina_novakova/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "standard_scaler.fit(final_df)\n",
    "\n",
    "X_train_standard_scaled = standard_scaler.transform(final_df)\n",
    "X_test_standard_scaled = standard_scaler.transform(final_test_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp_model(num_features, num_classes):\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(num_features,)),\n",
    "        Dropout(0.4),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compile the model with Adam optimizer and a learning rate of 0.01\n",
    "    model.compile(optimizer=Adam(learning_rate=0.01), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_mlp_model(78, 2)\n",
    "\n",
    "X = X_train_standard_scaled\n",
    "y = transformed_df['Overall_Experience']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2360/2360 [==============================] - 3s 1ms/step - loss: 0.2227 - accuracy: 0.9064 - val_loss: 0.1708 - val_accuracy: 0.9241 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "2360/2360 [==============================] - 2s 973us/step - loss: 0.1986 - accuracy: 0.9166 - val_loss: 0.1618 - val_accuracy: 0.9302 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "2360/2360 [==============================] - 2s 937us/step - loss: 0.1880 - accuracy: 0.9187 - val_loss: 0.1568 - val_accuracy: 0.9318 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "2360/2360 [==============================] - 2s 934us/step - loss: 0.1864 - accuracy: 0.9185 - val_loss: 0.1712 - val_accuracy: 0.9177 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "2360/2360 [==============================] - 2s 956us/step - loss: 0.1840 - accuracy: 0.9204 - val_loss: 0.1582 - val_accuracy: 0.9277 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "2360/2360 [==============================] - 2s 929us/step - loss: 0.1845 - accuracy: 0.9170 - val_loss: 0.1611 - val_accuracy: 0.9291 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "2360/2360 [==============================] - 2s 930us/step - loss: 0.1766 - accuracy: 0.9227 - val_loss: 0.1576 - val_accuracy: 0.9240 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "2360/2360 [==============================] - 2s 930us/step - loss: 0.1759 - accuracy: 0.9231 - val_loss: 0.1484 - val_accuracy: 0.9301 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "2360/2360 [==============================] - 2s 933us/step - loss: 0.1724 - accuracy: 0.9231 - val_loss: 0.1480 - val_accuracy: 0.9316 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "2360/2360 [==============================] - 2s 927us/step - loss: 0.1748 - accuracy: 0.9231 - val_loss: 0.1498 - val_accuracy: 0.9328 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "2360/2360 [==============================] - 2s 954us/step - loss: 0.1702 - accuracy: 0.9246 - val_loss: 0.1461 - val_accuracy: 0.9383 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "2360/2360 [==============================] - 2s 927us/step - loss: 0.1698 - accuracy: 0.9252 - val_loss: 0.1449 - val_accuracy: 0.9354 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "2360/2360 [==============================] - 2s 938us/step - loss: 0.1669 - accuracy: 0.9280 - val_loss: 0.1461 - val_accuracy: 0.9354 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "2360/2360 [==============================] - 2s 936us/step - loss: 0.1682 - accuracy: 0.9262 - val_loss: 0.1517 - val_accuracy: 0.9355 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "2360/2360 [==============================] - 2s 937us/step - loss: 0.1641 - accuracy: 0.9275 - val_loss: 0.1469 - val_accuracy: 0.9354 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "2360/2360 [==============================] - 2s 955us/step - loss: 0.1659 - accuracy: 0.9282 - val_loss: 0.1458 - val_accuracy: 0.9313 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "2301/2360 [============================>.] - ETA: 0s - loss: 0.1615 - accuracy: 0.9291\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "2360/2360 [==============================] - 2s 934us/step - loss: 0.1618 - accuracy: 0.9288 - val_loss: 0.1456 - val_accuracy: 0.9381 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "2360/2360 [==============================] - 2s 946us/step - loss: 0.1409 - accuracy: 0.9351 - val_loss: 0.1305 - val_accuracy: 0.9431 - lr: 1.0000e-03\n",
      "Epoch 19/200\n",
      "2360/2360 [==============================] - 2s 945us/step - loss: 0.1330 - accuracy: 0.9393 - val_loss: 0.1290 - val_accuracy: 0.9438 - lr: 1.0000e-03\n",
      "Epoch 20/200\n",
      "2360/2360 [==============================] - 2s 941us/step - loss: 0.1282 - accuracy: 0.9422 - val_loss: 0.1274 - val_accuracy: 0.9455 - lr: 1.0000e-03\n",
      "Epoch 21/200\n",
      "2360/2360 [==============================] - 2s 959us/step - loss: 0.1249 - accuracy: 0.9429 - val_loss: 0.1254 - val_accuracy: 0.9471 - lr: 1.0000e-03\n",
      "Epoch 22/200\n",
      "2360/2360 [==============================] - 2s 938us/step - loss: 0.1238 - accuracy: 0.9435 - val_loss: 0.1269 - val_accuracy: 0.9461 - lr: 1.0000e-03\n",
      "Epoch 23/200\n",
      "2360/2360 [==============================] - 2s 939us/step - loss: 0.1206 - accuracy: 0.9455 - val_loss: 0.1249 - val_accuracy: 0.9480 - lr: 1.0000e-03\n",
      "Epoch 24/200\n",
      "2360/2360 [==============================] - 2s 942us/step - loss: 0.1206 - accuracy: 0.9456 - val_loss: 0.1238 - val_accuracy: 0.9475 - lr: 1.0000e-03\n",
      "Epoch 25/200\n",
      "2360/2360 [==============================] - 2s 944us/step - loss: 0.1172 - accuracy: 0.9469 - val_loss: 0.1237 - val_accuracy: 0.9484 - lr: 1.0000e-03\n",
      "Epoch 26/200\n",
      "2360/2360 [==============================] - 2s 966us/step - loss: 0.1153 - accuracy: 0.9468 - val_loss: 0.1227 - val_accuracy: 0.9475 - lr: 1.0000e-03\n",
      "Epoch 27/200\n",
      "2360/2360 [==============================] - 2s 973us/step - loss: 0.1146 - accuracy: 0.9477 - val_loss: 0.1253 - val_accuracy: 0.9467 - lr: 1.0000e-03\n",
      "Epoch 28/200\n",
      "2360/2360 [==============================] - 2s 987us/step - loss: 0.1155 - accuracy: 0.9475 - val_loss: 0.1265 - val_accuracy: 0.9457 - lr: 1.0000e-03\n",
      "Epoch 29/200\n",
      "2360/2360 [==============================] - 2s 1ms/step - loss: 0.1129 - accuracy: 0.9495 - val_loss: 0.1222 - val_accuracy: 0.9492 - lr: 1.0000e-03\n",
      "Epoch 30/200\n",
      "2360/2360 [==============================] - 2s 948us/step - loss: 0.1129 - accuracy: 0.9490 - val_loss: 0.1224 - val_accuracy: 0.9491 - lr: 1.0000e-03\n",
      "Epoch 31/200\n",
      "2360/2360 [==============================] - 2s 939us/step - loss: 0.1130 - accuracy: 0.9487 - val_loss: 0.1229 - val_accuracy: 0.9489 - lr: 1.0000e-03\n",
      "Epoch 32/200\n",
      "2360/2360 [==============================] - 2s 936us/step - loss: 0.1115 - accuracy: 0.9494 - val_loss: 0.1219 - val_accuracy: 0.9509 - lr: 1.0000e-03\n",
      "Epoch 33/200\n",
      "2360/2360 [==============================] - 2s 939us/step - loss: 0.1109 - accuracy: 0.9497 - val_loss: 0.1250 - val_accuracy: 0.9500 - lr: 1.0000e-03\n",
      "Epoch 34/200\n",
      "2360/2360 [==============================] - 2s 952us/step - loss: 0.1093 - accuracy: 0.9507 - val_loss: 0.1227 - val_accuracy: 0.9510 - lr: 1.0000e-03\n",
      "Epoch 35/200\n",
      "2360/2360 [==============================] - 2s 936us/step - loss: 0.1087 - accuracy: 0.9501 - val_loss: 0.1257 - val_accuracy: 0.9462 - lr: 1.0000e-03\n",
      "Epoch 36/200\n",
      "2360/2360 [==============================] - 2s 939us/step - loss: 0.1088 - accuracy: 0.9501 - val_loss: 0.1231 - val_accuracy: 0.9496 - lr: 1.0000e-03\n",
      "Epoch 37/200\n",
      "2320/2360 [============================>.] - ETA: 0s - loss: 0.1075 - accuracy: 0.9512\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "2360/2360 [==============================] - 2s 992us/step - loss: 0.1077 - accuracy: 0.9511 - val_loss: 0.1236 - val_accuracy: 0.9506 - lr: 1.0000e-03\n",
      "Epoch 38/200\n",
      "2360/2360 [==============================] - 2s 985us/step - loss: 0.1043 - accuracy: 0.9530 - val_loss: 0.1228 - val_accuracy: 0.9509 - lr: 1.0000e-04\n",
      "Epoch 39/200\n",
      "2360/2360 [==============================] - 2s 983us/step - loss: 0.1057 - accuracy: 0.9521 - val_loss: 0.1222 - val_accuracy: 0.9508 - lr: 1.0000e-04\n",
      "Epoch 40/200\n",
      "2360/2360 [==============================] - 2s 1ms/step - loss: 0.1040 - accuracy: 0.9529 - val_loss: 0.1217 - val_accuracy: 0.9512 - lr: 1.0000e-04\n",
      "Epoch 41/200\n",
      "2360/2360 [==============================] - 2s 1ms/step - loss: 0.1045 - accuracy: 0.9531 - val_loss: 0.1211 - val_accuracy: 0.9511 - lr: 1.0000e-04\n",
      "Epoch 42/200\n",
      "2360/2360 [==============================] - 2s 960us/step - loss: 0.1046 - accuracy: 0.9526 - val_loss: 0.1215 - val_accuracy: 0.9510 - lr: 1.0000e-04\n",
      "Epoch 43/200\n",
      "2360/2360 [==============================] - 2s 1ms/step - loss: 0.1030 - accuracy: 0.9532 - val_loss: 0.1213 - val_accuracy: 0.9509 - lr: 1.0000e-04\n",
      "Epoch 44/200\n",
      "2360/2360 [==============================] - 2s 991us/step - loss: 0.1036 - accuracy: 0.9528 - val_loss: 0.1212 - val_accuracy: 0.9514 - lr: 1.0000e-04\n",
      "Epoch 45/200\n",
      "2360/2360 [==============================] - 2s 1ms/step - loss: 0.1038 - accuracy: 0.9531 - val_loss: 0.1211 - val_accuracy: 0.9514 - lr: 1.0000e-04\n",
      "Epoch 46/200\n",
      "2360/2360 [==============================] - 2s 945us/step - loss: 0.1035 - accuracy: 0.9528 - val_loss: 0.1209 - val_accuracy: 0.9515 - lr: 1.0000e-04\n",
      "Epoch 47/200\n",
      "2360/2360 [==============================] - 2s 948us/step - loss: 0.1037 - accuracy: 0.9532 - val_loss: 0.1218 - val_accuracy: 0.9517 - lr: 1.0000e-04\n",
      "Epoch 48/200\n",
      "2360/2360 [==============================] - 2s 949us/step - loss: 0.1044 - accuracy: 0.9531 - val_loss: 0.1211 - val_accuracy: 0.9508 - lr: 1.0000e-04\n",
      "Epoch 49/200\n",
      "2360/2360 [==============================] - 2s 949us/step - loss: 0.1031 - accuracy: 0.9530 - val_loss: 0.1221 - val_accuracy: 0.9510 - lr: 1.0000e-04\n",
      "Epoch 50/200\n",
      "2360/2360 [==============================] - 2s 973us/step - loss: 0.1025 - accuracy: 0.9534 - val_loss: 0.1216 - val_accuracy: 0.9517 - lr: 1.0000e-04\n",
      "Epoch 51/200\n",
      "2310/2360 [============================>.] - ETA: 0s - loss: 0.1032 - accuracy: 0.9525\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "2360/2360 [==============================] - 2s 949us/step - loss: 0.1034 - accuracy: 0.9523 - val_loss: 0.1216 - val_accuracy: 0.9505 - lr: 1.0000e-04\n",
      "Epoch 52/200\n",
      "2360/2360 [==============================] - 2s 952us/step - loss: 0.1036 - accuracy: 0.9524 - val_loss: 0.1214 - val_accuracy: 0.9507 - lr: 1.0000e-05\n",
      "Epoch 53/200\n",
      "2360/2360 [==============================] - 2s 949us/step - loss: 0.1028 - accuracy: 0.9529 - val_loss: 0.1213 - val_accuracy: 0.9510 - lr: 1.0000e-05\n",
      "Epoch 54/200\n",
      "2360/2360 [==============================] - 2s 965us/step - loss: 0.1016 - accuracy: 0.9539 - val_loss: 0.1213 - val_accuracy: 0.9511 - lr: 1.0000e-05\n",
      "Epoch 55/200\n",
      "2360/2360 [==============================] - 2s 950us/step - loss: 0.1029 - accuracy: 0.9531 - val_loss: 0.1213 - val_accuracy: 0.9511 - lr: 1.0000e-05\n",
      "Epoch 56/200\n",
      "2360/2360 [==============================] - 2s 947us/step - loss: 0.1022 - accuracy: 0.9534 - val_loss: 0.1213 - val_accuracy: 0.9512 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "# Convert target labels to one-hot encoded categorical format\n",
    "y_categorical = to_categorical(y, num_classes=2)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "split_index = int(94380 * 0.8)\n",
    "X_train, X_val = X[:split_index], X[split_index:]\n",
    "y_train, y_val = y_categorical[:split_index], y_categorical[split_index:]\n",
    "\n",
    "# Train the model\n",
    "epochs = 200\n",
    "batch_size = 32\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, min_lr=1e-5)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val), callbacks=[early_stopping, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1113/1113 [==============================] - 1s 449us/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "predictions = model.predict(X_test_standard_scaled)\n",
    "\n",
    "# The predictions variable contains probability distributions over the classes for each test sample\n",
    "# You can convert these probabilities to class labels by choosing the class with the highest probability\n",
    "predicted_labels = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall_Experience</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99900001</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99900002</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99900003</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99900004</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99900005</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99935598</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99935599</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99935600</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99935601</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99935602</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35602 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Overall_Experience\n",
       "ID                          \n",
       "99900001                   0\n",
       "99900002                   1\n",
       "99900003                   1\n",
       "99900004                   0\n",
       "99900005                   1\n",
       "...                      ...\n",
       "99935598                   0\n",
       "99935599                   0\n",
       "99935600                   0\n",
       "99935601                   1\n",
       "99935602                   0\n",
       "\n",
       "[35602 rows x 1 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(data={'ID': range(99900001,99935603), 'Overall_Experience': predicted_labels}).set_index('ID').sort_index(ascending=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('Sample_Submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
