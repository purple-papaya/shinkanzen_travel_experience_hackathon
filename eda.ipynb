{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder, KBinsDiscretizer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomOrdinalEncoder:\n",
    "    def __init__(self, categories):\n",
    "        self.categories = categories\n",
    "        self.cat_to_int = {}\n",
    "        self.int_to_cat = {}\n",
    "        for i, cat in enumerate(self.categories):\n",
    "            self.cat_to_int[cat] = i\n",
    "            self.int_to_cat[i] = cat\n",
    "\n",
    "    def transform(self, data):\n",
    "        return np.array([self.cat_to_int[cat] if cat in self.cat_to_int else np.nan for cat in data])\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        return np.array([self.int_to_cat[int(cat)] for cat in data])\n",
    "\n",
    "def encode_ordinal_columns(df, ordinal_columns, n_classes):\n",
    "    encoders = {}\n",
    "    encoded_df = df.copy()\n",
    "    for col in ordinal_columns:\n",
    "        unique_values = sorted(df[col].dropna().unique())\n",
    "        categories = unique_values + [f\"extra_class_{i}\" for i in range(n_classes - len(unique_values))]\n",
    "        encoder = CustomOrdinalEncoder(categories)\n",
    "        encoded_df[col] = encoder.transform(df[col])\n",
    "        encoders[col] = encoder\n",
    "    return encoded_df, encoders\n",
    "\n",
    "def impute_missing_ordinal_records(df, ordinal_columns, n_classes=5, max_iter=10, random_state=42):\n",
    "    encoded_df, encoders = encode_ordinal_columns(df, ordinal_columns, n_classes)\n",
    "    \n",
    "    imputer = IterativeImputer(max_iter=max_iter, estimator=RandomForestRegressor(random_state=random_state), random_state=random_state)\n",
    "    imputed_array = imputer.fit_transform(encoded_df)\n",
    "\n",
    "    imputed_df = pd.DataFrame(imputed_array, columns=df.columns)\n",
    "    imputed_df[ordinal_columns] = np.round(imputed_df[ordinal_columns])\n",
    "\n",
    "    for col in ordinal_columns:\n",
    "        imputed_df[col] = encoders[col].inverse_transform(imputed_df[col])\n",
    "\n",
    "    return imputed_df\n",
    "\n",
    "def encode_non_ordinal_columns(df, non_ordinal_columns):\n",
    "    encoded_df = pd.get_dummies(df, columns=non_ordinal_columns, drop_first=True)\n",
    "    return encoded_df\n",
    "\n",
    "def impute_missing_non_ordinal_records(df, max_iter=10, random_state=42):\n",
    "    imputer = IterativeImputer(max_iter=max_iter, estimator=RandomForestRegressor(random_state=random_state), random_state=random_state)\n",
    "    imputed_array = imputer.fit_transform(df)\n",
    "\n",
    "    imputed_df = pd.DataFrame(imputed_array, columns=df.columns)\n",
    "    return imputed_df\n",
    "\n",
    "def impute_most_common(df):\n",
    "    for column in df.columns:\n",
    "        most_common_value = df[column].mode()[0]\n",
    "        df[column].fillna(most_common_value, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Custom colors\n",
    "class clr:\n",
    "    S = '\\033[1m' + '\\033[92m'\n",
    "    E = '\\033[0m'\n",
    "\n",
    "# The custom colors chosen here were generated by 'I want hue' app. \n",
    "# The were chosen for color-blindness.\n",
    "our_colors = [\"#af953c\", \"#6971c9\", \"#56ae6c\",\n",
    "             \"#a24f99\", \"#ba4a4f\"]\n",
    "\n",
    "# Optionally, create a color map, particularly for future use.\n",
    "CMAP1 = ListedColormap(our_colors)\n",
    "\n",
    "# Display our own color scheme, as a reference.\n",
    "print(clr.S+'Notebook Color Scheme:\\n'+clr.E)\n",
    "sns.palplot(sns.color_palette(our_colors))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df = pd.read_csv(\"Surveydata_train.csv\")\n",
    "survey_df_test = pd.read_csv(\"Surveydata_test.csv\")\n",
    "display(survey_df.head())\n",
    "display(survey_df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(survey_df.info())\n",
    "display(survey_df_test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(survey_df.iloc[:,2:17].describe(include = 'all'))\n",
    "display(survey_df_test.iloc[:,1:16].describe(include = 'all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(survey_df.isna().sum())\n",
    "display(survey_df_test.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_df = pd.read_csv(\"Traveldata_train.csv\")\n",
    "display(travel_df.head())\n",
    "travel_df_test = pd.read_csv(\"Traveldata_test.csv\")\n",
    "display(travel_df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(travel_df.info())\n",
    "display(travel_df_test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(travel_df.iloc[:,1:9].describe(include ='all'))\n",
    "display(travel_df_test.iloc[:,1:9].describe(include ='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(travel_df.isna().sum())\n",
    "display(travel_df_test.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two datasets\n",
    "\n",
    "merged_df = pd.merge(survey_df, travel_df, on= 'ID')\n",
    "display(merged_df.head())\n",
    "\n",
    "merged_df_test = pd.merge(survey_df_test, travel_df_test, on= 'ID')\n",
    "display(merged_df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of the original and merged data\n",
    "display(travel_df.shape)\n",
    "display(survey_df.shape)\n",
    "display(merged_df.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(merged_df.info())\n",
    "display(merged_df_test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(merged_df.isna().sum())\n",
    "display(merged_df_test.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df = (\n",
    "    merged_df\n",
    "    # 'Seat_comfort', 'Arrival_time_convenient', 'Catering', 'Onboardwifi_service', 'Onboard_entertainment', 'Online_support',\n",
    "    # 'Onlinebooking_Ease', 'Onboard_service', 'Leg_room', 'Checkin_service', 'Cleanliness', 'Online_boarding'\n",
    "    .replace(['excellent', 'good', 'acceptable', 'need improvement', 'poor', 'extremely poor'], [5, 4, 3, 2, 1, 0])\n",
    "    # Platform_location\n",
    "    .replace(['very convinient', 'Convinient', 'manageable', 'need improvement', 'Inconvinient', 'very inconvinient'], [5, 4, 3, 2, 1, 0])\n",
    "    # Seat_Class\n",
    "    .replace(['Ordinary', 'Green Car'], [0, 1])\n",
    "    # Baggage_handling\n",
    "    .replace(['need improvement', 'poor', 'excellent', 'acceptable', 'good'], [2, 1, 5, 3, 4])\n",
    "    # Gender\n",
    "    .replace(['Male', 'Female'], [0, 1])\n",
    "    # CustomerType\n",
    "    .replace(['disloyal Customer', 'Loyal Customer'], [0, 1])\n",
    "    # TypeTravel\n",
    "    .replace(['Personal Travel', 'Business travel'], [0, 1])\n",
    "    # Travel_Class\n",
    "    .replace(['Eco', 'Business'], [0, 1])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_test_df = (\n",
    "    merged_df_test\n",
    "    .replace(['excellent', 'good', 'acceptable', 'need improvement', 'poor', 'extremely poor'], [5, 4, 3, 2, 1, 0])\n",
    "    .replace(['very convinient', 'Convinient', 'manageable', 'need improvement', 'Inconvinient', 'very inconvinient'], [5, 4, 3, 2, 1, 0])\n",
    "    .replace(['Ordinary', 'Green Car'], [0, 1])\n",
    "    .replace(['need improvement', 'poor', 'excellent', 'acceptable', 'good'], [2, 1, 5, 3, 4])\n",
    "    .replace(['Male', 'Female'], [0, 1])\n",
    "    .replace(['disloyal Customer', 'Loyal Customer'], [0, 1])\n",
    "    .replace(['Personal Travel', 'Business travel'], [0, 1])\n",
    "    .replace(['Eco', 'Business'], [0, 1])\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for distinct values of the data.\n",
    "\n",
    "Looking at the heatmap, we see the correlation among the various features. Grouping together the values of these correlated features gives as an indication of how we may imput the missing values.\n",
    "\n",
    "A better idea would probably be to plot these...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall_Experience and Onboard_entertainment\n",
    "merged_df.groupby(['Overall_Experience', 'Onboard_entertainment'])['Overall_Experience', 'Onboard_entertainment'].value_counts().reset_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop data or impute?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(len(merged_df))\n",
    "display(len(merged_df.dropna()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** By dropping data, we'd loose almost half the dataset. Ramona's researched suggested a multivariate iterative imputer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_columns = [\n",
    "    'Seat_comfort', 'Arrival_time_convenient', 'Catering', 'Platform_location', 'Onboardwifi_service', \n",
    "    'Onboard_entertainment', 'Online_support', 'Onlinebooking_Ease', 'Onboard_service', \n",
    "    'Leg_room', 'Baggage_handling', 'Checkin_service', 'Cleanliness', 'Online_boarding'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_imputed = impute_missing_ordinal_records(transformed_df[ordinal_columns], ordinal_columns, n_classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [\n",
    "    'Seat_Class', 'Gender', 'CustomerType', 'TypeTravel', 'Travel_Class'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_non_ordinal_df = encode_non_ordinal_columns(transformed_df[categorical_columns], categorical_columns)\n",
    "\n",
    "encoded_df = pd.concat([encoded_non_ordinal_df, ordinal_imputed], axis=1)\n",
    "\n",
    "categorical_imputed = impute_missing_non_ordinal_records(encoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_data = [\n",
    "    'ID', 'Overall_Experience', 'Age', 'Travel_Distance', 'DepartureDelay_in_Mins', 'ArrivalDelay_in_Mins'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df[numerical_data].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = impute_most_common(pd.concat([categorical_imputed, transformed_df[numerical_data]], axis=1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions**: \n",
    " - Categorical and non-categorical data were imputed with a multivariate imputer.\n",
    " - Remaining missing numerical values (approx. 500) were imputed with the most common value."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing Cleanliness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[merged_df['Cleanliness'].isna()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**: Missing Cleanliness values are predominantly for fairly poor experiences: \n",
    " - Overall_Experience 1\n",
    " - Seat_comfort extremely poor\n",
    " - Seat_Class Green Car\n",
    " - Arrival_time_convenient poor\n",
    " - Catering extremely poor\n",
    " - Platform_location manageable\n",
    " - Onboard_entertainment extremely poor\n",
    " - TypeTravel Personal Travel\n",
    " - Travel_Class Eco\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_cleanliness = merged_df.query(\"Overall_Experience == 1 & Seat_comfort == 'extremely poor' & Seat_Class == 'Green Car' & Arrival_time_convenient == 'poor' & Catering == 'extremely poor' & Platform_location == 'manageable' & Onboard_entertainment == 'extremely poor' & TypeTravel == 'Personal Travel' & Travel_Class == 'Eco'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_cleanliness['Cleanliness'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_cleanliness.dropna(subset=['Cleanliness'])[['Online_support', 'Onboardwifi_service', 'Age', 'Cleanliness']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_cleanliness = transformed_df[['Online_support', 'Onboardwifi_service', 'Cleanliness']]\n",
    "sns.barplot(data=tech_cleanliness, x='Online_support', y='Cleanliness', hue='Onboardwifi_service', palette=our_colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[merged_df['Cleanliness'].isna()][['Online_support', 'Onboardwifi_service', 'Cleanliness']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_age_cleanliness = transformed_df[['Age', 'Gender', 'Cleanliness']]\n",
    "gender_age_cleanliness['Age'] = pd.cut(merged_df['Age'], 5, labels = ['25', '35', '45', '60', '80'])\n",
    "sns.barplot(data=gender_age_cleanliness, x='Age', y='Cleanliness', hue='Gender')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** \n",
    "From exploring the dataset, it seems that:\n",
    " - Cleanliness rating is independent of Gender and Age.\n",
    " - Cleanliness depends more on tech services, like wifi and online support.\n",
    " - Similar reviews to the ones that need to be imputed are Acceptable/Good in a 1:1 ratio.\n",
    " - Based on the bar chart comparing Cleanliness values per wifi and online support rating, I'd suggest imputing 'good' for all but one missing value (the one is a combination of 'need improvement' for online support and 'acceptable' for wifi)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing Online boarding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[merged_df['Online_boarding'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_boarding = merged_df.query(\"Overall_Experience == 1 & Seat_comfort == 'extremely poor' & Seat_Class == 'Green Car' & Arrival_time_convenient == 'poor' & Catering == 'extremely poor' & Platform_location == 'manageable' & Onboard_entertainment == 'extremely poor' & TypeTravel == 'Personal Travel' & Travel_Class == 'Eco'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_boarding['Online_boarding'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_boarding = transformed_df[['Online_support', 'Onboardwifi_service', 'Online_boarding']]\n",
    "sns.barplot(data=tech_boarding, x='Online_support', y='Online_boarding', hue='Onboardwifi_service', palette=our_colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[merged_df['Online_boarding'].isna()][['Online_support', 'Onboardwifi_service', 'Online_boarding']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_age_boarding = transformed_df[['Age', 'Gender', 'Online_boarding']]\n",
    "gender_age_boarding['Age'] = pd.cut(merged_df['Age'], 5, labels = ['25', '35', '45', '60', '80'])\n",
    "sns.barplot(data=gender_age_boarding, x='Age', y='Online_boarding', hue='Gender')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions**:\n",
    " - Online boarding depends highly on other tech services.\n",
    " - Doesn't depend that much on age or gender.\n",
    " - I'd suggest an imputation based on the bar chart of other tech services: 'excellent' for both excellent rows, 'poor' for both poor rows, 'good' for the good row and 'acceptable' for the remaining row."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing Onboard entertainment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(transformed_df.corr(), cmap=\"rocket_r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=transformed_df[['Online_support', 'Seat_comfort', 'Onboard_entertainment']], x='Online_support', y='Onboard_entertainment', hue='Seat_comfort', palette=our_colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun_df = merged_df[['Overall_Experience', 'Online_support', 'Seat_comfort']].dropna()\n",
    "fun_df['Onboard_entertainment'] = merged_df['Onboard_entertainment']\n",
    "\n",
    "fun_imputed = impute_missing_ordinal_records(fun_df, list(fun_df.columns), n_classes=5)\n",
    "fun_imputed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions**:\n",
    " - Onboard entertainment is correlated with Overall experience, Online Support and Seat Comfort\n",
    " - Imputation can use all three parameters to fill in the missing values\n",
    " - An imputer of categorical ordinal data was created"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing Platform location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['Platform_location'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(transformed_df.corr(), cmap=\"rocket_r\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Heatmap** for `transformed_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(transformed_df.corr(), cmap=CMAP1)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the heatmap we can conclude:\n",
    "  - Strong correlation between `Overall_Experience` and `Onboard_entertainment`, `Onlinebooking_Ease`, `Onboard_service`, `Online_support`.\n",
    "    - I want to analyze this further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=transformed_df, x='Overall_Experience', y='Onboard_entertainment', hue='Onlinebooking_Ease', palette=our_colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=transformed_df, x='Arrival_time_convenient', y='Platform_location', hue='Catering', palette=our_colors)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions:**\n",
    " - Platform location has new set of categorie: 'very convinient', 'Convinient', 'manageable', 'need improvement', 'Inconvinient', 'very inconvinient'\n",
    " - Platform location is correlated with Arrival time convenience and Catering\n",
    " - Imputer was created to impute missing data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "winters_in_moravia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
